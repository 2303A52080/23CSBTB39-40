{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjJvZAJEk92ULwCijcJlO5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52080/23CSBTB39-40/blob/main/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment-4;\n",
        "\n",
        "1 Implement Linear Regression Model Using US Housing Data\n",
        "\n",
        "Part 1 â€“ Import the required Python, Pandas, Matplotlib, Seaborn packages.\n",
        "\n",
        "\n",
        "1. Load the US Housing data into a dataframe using pandas\n",
        "\n",
        "2. Check the data types of each feature(column) in the dataset.\n",
        "\n",
        "3. Generate a summary of the dataset for min, max, stddev,\n",
        "quartile vales for 25%,50%,75%,90%,\n",
        "\n",
        "4. List the names of columns/features in the dataset\n",
        "\n",
        "5. Generate a pairplot of the features of the dataset.\n",
        "\n",
        "6. Generate a correlation matrix and heatmap for the features\n",
        "\n",
        "7. Create a list of dependent variable to independent variables to understand\n",
        "regression among the features. From the data include Price to other numerical variables of the Housing data."
      ],
      "metadata": {
        "id": "4mPaMJ-iQweK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the US Housing data into a dataframe using pandas\n",
        "df = pd.read_csv('USA_Housing.csv')\n",
        "\n",
        "# Check the data types of each feature(column) in the dataset.\n",
        "print(df.dtypes)\n",
        "\n",
        "# Generate a summary of the dataset\n",
        "print(df.describe(percentiles=[.25, .5, .75, .9]))\n",
        "\n",
        "# List the names of columns/features in the dataset\n",
        "print(df.columns)\n",
        "\n",
        "# Generate a pairplot of the features of the dataset.\n",
        "sns.pairplot(df)\n",
        "plt.show()\n",
        "\n",
        "# Generate a correlation matrix and heatmap for the features\n",
        "# Convert non-numeric columns to numeric if needed\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        try:\n",
        "            df[col] = pd.to_numeric(df[col])\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert column {col} to numeric\")"
      ],
      "metadata": {
        "id": "S7nHd5W1Q171"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part-2"
      ],
      "metadata": {
        "id": "ezt2C6t-Q6Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('USA_Housing.csv')\n",
        "\n",
        "# Display the first few rows and data types\n",
        "print(df.head())\n",
        "print(df.dtypes)\n",
        "\n",
        "# Assume 'price' is the target variable and all other columns are features\n",
        "X = df.drop(columns='price')  # Features\n",
        "Y = df['price']               # Target variable\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(), categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Create a pipeline that includes preprocessing and the model\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "pipeline.fit(X_train, Y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "Y_pred = pipeline.predict(X_test)\n",
        "residuals = Y_test - Y_pred\n",
        "\n",
        "# Compute CDF\n",
        "sorted_residuals = np.sort(residuals)\n",
        "cdf = np.arange(1, len(sorted_residuals) + 1) / len(sorted_residuals)\n",
        "\n",
        "# Plot CDF\n",
        "plt.figure()\n",
        "plt.plot(sorted_residuals, cdf, marker='.', linestyle='none')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('CDF')\n",
        "plt.title('Cumulative Distribution Function of Residuals')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Optional: Evaluate the model\n",
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "# Get model parameters\n",
        "model = pipeline.named_steps['model']\n",
        "intercept = model.intercept_\n",
        "slope = model.coef_\n",
        "print(f'Intercept: {intercept}')\n",
        "print(f'Slope: {slope}')\n"
      ],
      "metadata": {
        "id": "ohm8dX33Q9Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part-3"
      ],
      "metadata": {
        "id": "gfjyjjXZQ_pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('USA_Housing.csv')\n",
        "\n",
        "# Display the first few rows and data types\n",
        "print(df.head())\n",
        "print(df.dtypes)\n",
        "\n",
        "# Prepare the data\n",
        "X = df.drop(columns='price')  # Features\n",
        "Y = df['price']               # Target variable\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(), categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Create a pipeline that includes preprocessing and the model\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "pipeline.fit(X_train, Y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "Y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate residuals\n",
        "residuals = Y_test - Y_pred\n",
        "\n",
        "# Get the coefficients for the model\n",
        "model = pipeline.named_steps['model']\n",
        "coefficients = model.coef_\n",
        "\n",
        "# Adding intercept to feature matrix for statsmodels\n",
        "X_train_transformed = pipeline.named_steps['preprocessor'].transform(X_train)\n",
        "X_train_const = sm.add_constant(X_train_transformed)\n",
        "\n",
        "# Fit statsmodels OLS model\n",
        "ols_model = sm.OLS(Y_train, X_train_const).fit()\n",
        "\n",
        "print(\"\\nStandard Error of Coefficients:\")\n",
        "print(ols_model.bse)  # Standard error of the coefficients\n",
        "\n",
        "print(\"\\nT-statistic of Coefficients:\")\n",
        "print(ols_model.tvalues)  # T-statistic of the coefficients\n",
        "\n",
        "# Compute CDF of coefficients\n",
        "sorted_coefficients = np.sort(coefficients)\n",
        "cdf = np.arange(1, len(sorted_coefficients) + 1) / len(sorted_coefficients)\n",
        "\n",
        "# Plot CDF of coefficients\n",
        "plt.figure()\n",
        "plt.plot(sorted_coefficients, cdf, marker='.', linestyle='none')\n",
        "plt.xlabel('Coefficients')\n",
        "plt.ylabel('CDF')\n",
        "plt.title('Cumulative Distribution Function of Coefficients')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Scatter plots for features vs. Price\n",
        "for feature in X.columns:\n",
        "    plt.figure()\n",
        "    plt.scatter(X_test[feature], Y_test, label='True Values', alpha=0.5)\n",
        "    plt.scatter(X_test[feature], Y_pred, label='Predicted Values', alpha=0.5)\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Price')\n",
        "    plt.title(f'Scatter Plot of {feature} vs Price')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Compute RÂ²\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "print(f'RÂ² Score: {r2}')\n",
        "\n",
        "# Plot predictions - histogram and scatter plot\n",
        "plt.figure()\n",
        "plt.hist(Y_pred, bins=30, alpha=0.7, label='Predicted Prices')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Predicted Prices')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(Y_test, Y_pred, alpha=0.5)\n",
        "plt.xlabel('True Prices')\n",
        "plt.ylabel('Predicted Prices')\n",
        "plt.title('Scatter Plot of True vs Predicted Prices')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Evaluation metrics\n",
        "mae = mean_absolute_error(Y_test, Y_pred)\n",
        "sse = np.sum((Y_test - Y_pred) ** 2)\n",
        "rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
        "\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'Sum of Squared Errors (SSE): {sse}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "print(f'RÂ² Score: {r2}')\n"
      ],
      "metadata": {
        "id": "gYQORymRRCqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('USA_Housing.csv')\n",
        "\n",
        "# Display the first few rows to understand the structure\n",
        "print(df.head())\n",
        "\n",
        "# Select the feature to normalize, for example 'Price'\n",
        "feature = 'price'\n",
        "data = df[feature]\n",
        "\n",
        "# Compute Min-Max normalization\n",
        "min_value = data.min()\n",
        "max_value = data.max()\n",
        "data_minmax = (data - min_value) / (max_value - min_value)\n",
        "\n",
        "# Print the Min-Max normalized values\n",
        "print(f\"Min-Max Normalized values for feature '{feature}':\")\n",
        "print(data_minmax.head())\n",
        "\n",
        "# Plot the distribution of the original feature\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Original feature distribution\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data, bins=30, alpha=0.7, color='blue')\n",
        "plt.xlabel('Original Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Original Price')\n",
        "\n",
        "# Normalized feature distribution\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(data_minmax, bins=30, alpha=0.7, color='green')\n",
        "plt.xlabel('Normalized Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Normalized Price')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "3eOnaZF7RHXD",
        "outputId": "fb9745be-0796-444d-efd7-905a23dc2f19"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'USA_Housing.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cb9c3a754f05>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'USA_Housing.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Display the first few rows to understand the structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'USA_Housing.csv'"
          ]
        }
      ]
    }
  ]
}