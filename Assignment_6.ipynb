{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOam+rljJdbIqpgysDQX8kV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52080/23CSBTB39-40/blob/main/Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1 – Import the required Python, Pandas, Matplotlib, Seaborn packages.\n",
        "[CO1]\n",
        "1. Load the classified dataset into a dataframe using pandas\n",
        "2. Check the data types of each feature(column) in the dataset.\n",
        "3. Generate a summary of the dataset for min, max, stddev,\n",
        "quartile vales for 25%,50%,75%,90%,\n",
        "4. List the names of columns/features in the dataset\n",
        "5. Scale the features using StandardScaler and transform the data"
      ],
      "metadata": {
        "id": "BsnvZguhWDaF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6cgv0K7VrJX",
        "outputId": "74bbe549-160a-4279-ea03-e6920945b687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0       WTT       PTI       EQW       SBI       LQE       QWG  \\\n",
            "0           0  0.913917  1.162073  0.567946  0.755464  0.780862  0.352608   \n",
            "1           1  0.635632  1.003722  0.535342  0.825645  0.924109  0.648450   \n",
            "2           2  0.721360  1.201493  0.921990  0.855595  1.526629  0.720781   \n",
            "3           3  1.234204  1.386726  0.653046  0.825624  1.142504  0.875128   \n",
            "4           4  1.279491  0.949750  0.627280  0.668976  1.232537  0.703727   \n",
            "\n",
            "        FDJ       PJF       HQE       NXJ  TARGET CLASS  \n",
            "0  0.759697  0.643798  0.879422  1.231409             1  \n",
            "1  0.675334  1.013546  0.621552  1.492702             0  \n",
            "2  1.626351  1.154483  0.957877  1.285597             0  \n",
            "3  1.409708  1.380003  1.522692  1.153093             1  \n",
            "4  1.115596  0.646691  1.463812  1.419167             1  \n",
            "\n",
            "Data types:\n",
            " Unnamed: 0        int64\n",
            "WTT             float64\n",
            "PTI             float64\n",
            "EQW             float64\n",
            "SBI             float64\n",
            "LQE             float64\n",
            "QWG             float64\n",
            "FDJ             float64\n",
            "PJF             float64\n",
            "HQE             float64\n",
            "NXJ             float64\n",
            "TARGET CLASS      int64\n",
            "dtype: object\n",
            "\n",
            "Summary statistics:\n",
            "         Unnamed: 0          WTT          PTI          EQW          SBI  \\\n",
            "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
            "mean    499.500000     0.949682     1.114303     0.834127     0.682099   \n",
            "std     288.819436     0.289635     0.257085     0.291554     0.229645   \n",
            "min       0.000000     0.174412     0.441398     0.170924     0.045027   \n",
            "25%     249.750000     0.742358     0.942071     0.615451     0.515010   \n",
            "50%     499.500000     0.940475     1.118486     0.813264     0.676835   \n",
            "75%     749.250000     1.163295     1.307904     1.028340     0.834317   \n",
            "90%     899.100000     1.336612     1.441901     1.223127     0.983470   \n",
            "max     999.000000     1.721779     1.833757     1.722725     1.634884   \n",
            "\n",
            "               LQE          QWG          FDJ          PJF          HQE  \\\n",
            "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
            "mean      1.032336     0.943534     0.963422     1.071960     1.158251   \n",
            "std       0.243413     0.256121     0.255118     0.288982     0.293738   \n",
            "min       0.315307     0.262389     0.295228     0.299476     0.365157   \n",
            "25%       0.870855     0.761064     0.784407     0.866306     0.934340   \n",
            "50%       1.035824     0.941502     0.945333     1.065500     1.165556   \n",
            "75%       1.198270     1.123060     1.134852     1.283156     1.383173   \n",
            "90%       1.341138     1.277552     1.306497     1.452713     1.535520   \n",
            "max       1.650050     1.666902     1.713342     1.785420     1.885690   \n",
            "\n",
            "               NXJ  TARGET CLASS  \n",
            "count  1000.000000    1000.00000  \n",
            "mean      1.362725       0.50000  \n",
            "std       0.204225       0.50025  \n",
            "min       0.639693       0.00000  \n",
            "25%       1.222623       0.00000  \n",
            "50%       1.375368       0.50000  \n",
            "75%       1.504832       1.00000  \n",
            "90%       1.618096       1.00000  \n",
            "max       1.893950       1.00000  \n",
            "\n",
            "Column names: ['Unnamed: 0', 'WTT', 'PTI', 'EQW', 'SBI', 'LQE', 'QWG', 'FDJ', 'PJF', 'HQE', 'NXJ', 'TARGET CLASS']\n",
            "\n",
            "Scaled features:\n",
            "    Unnamed: 0       WTT       PTI       EQW       SBI       LQE       QWG  \\\n",
            "0   -1.730320 -0.123542  0.185907 -0.913431  0.319629 -1.033637 -2.308375   \n",
            "1   -1.726856 -1.084836 -0.430348 -1.025313  0.625388 -0.444847 -1.152706   \n",
            "2   -1.723391 -0.788702  0.339318  0.301511  0.755873  2.031693 -0.870156   \n",
            "3   -1.719927  0.982841  1.060193 -0.621399  0.625299  0.452820 -0.267220   \n",
            "4   -1.716463  1.139275 -0.640392 -0.709819 -0.057175  0.822886 -0.936773   \n",
            "\n",
            "        FDJ       PJF       HQE       NXJ  \n",
            "0 -0.798951 -1.482368 -0.949719 -0.643314  \n",
            "1 -1.129797 -0.202240 -1.828051  0.636759  \n",
            "2  2.599818  0.285707 -0.682494 -0.377850  \n",
            "3  1.750208  1.066491  1.241325 -1.026987  \n",
            "4  0.596782 -1.472352  1.040772  0.276510  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "df = pd.read_csv('Classified_Data.csv')\n",
        "print(df.head())\n",
        "print(\"\\nData types:\\n\", df.dtypes)\n",
        "summary = df.describe(percentiles=[.25, .5, .75, .90])\n",
        "print(\"\\nSummary statistics:\\n\", summary)\n",
        "column_names = df.columns.tolist()\n",
        "print(\"\\nColumn names:\", column_names)\n",
        "features = df.iloc[:, :-1]\n",
        "target = df.iloc[:, -1]\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
        "print(\"\\nScaled features:\\n\", scaled_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2 – Model training and Fit the data to Model. [CO2]\n",
        "1. Split the data generated from list created as X, Y is distributed using train test split\n",
        "function as X train, Y train, X test, Y test\n",
        "2. Apply the KNN Classifier model of sklearn.neighbors import KNeighborsClassifier\n",
        "package\n",
        "3. Fit the data to the Classier Model using fit."
      ],
      "metadata": {
        "id": "i_3e67mXWXUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 1. Split the data generated from list created as X, Y is distributed using train test split\n",
        "# function as X train, Y train, X test, Y test\n",
        "# 2. Apply the KNN Classifier model of sklearn.neighbors import KNeighborsClassifier\n",
        "# package\n",
        "# 3. Fit the data to the Classier Model using fit.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# 1. Split the data\n",
        "X = scaled_data\n",
        "y = data['target_column']  # Replace 'target_column' with the name of your target column\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Adjust test_size as needed\n",
        "\n",
        "# 2. Apply the KNN Classifier model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # Adjust n_neighbors as needed\n",
        "\n",
        "# 3. Fit the data to the Classifier Model\n",
        "knn.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "SptzsIkxWnR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Generate the confusion matrix to estimate the correction among features\n",
        "2. Generate the classification report using classification report\n",
        "1\n"
      ],
      "metadata": {
        "id": "puQiGA7LW0m5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 1. Generate the confusion matrix to estimate the correction among features\n",
        "# 2. Generate the classification report using classification report 1\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# 1. Generate the confusion matrix\n",
        "y_pred = knn.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# 2. Generate the classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(cr)\n"
      ],
      "metadata": {
        "id": "5evGwJCWW1Pw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}